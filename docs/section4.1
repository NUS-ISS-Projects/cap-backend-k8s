4.1 Performance
Performance in this system is defined by its ability to handle a high-volume stream of DIS PDU data, process it with low latency, and serve queries efficiently. The architecture is designed with several key principles to meet these requirements, including asynchronous processing, horizontal scalability, and optimized data handling.
High-Throughput PDU Ingestion:
UDP Listener for Low-Overhead Ingestion: The data-ingestion-service utilizes a UDP listener (UdpListenerService.java) to receive DIS PDUs. UDP is strategically chosen for its minimal overhead compared to TCP. In a high-volume, real-time environment like DIS, the speed of data reception is critical, and the stateless nature of UDP allows the service to handle a massive influx of packets without the latency of connection handshakes.
Asynchronous and Non-Blocking Operations: The entire UDP listening and processing pipeline is fully asynchronous (@Async). This ensures that the main application thread is never blocked by network I/O. By immediately offloading packet handling to a separate thread pool, the service remains responsive and can continuously accept new data, preventing packet loss during traffic bursts.
Efficient PDU Decoding and Serialization:
PDUs are decoded using the edu.nps.moves.disutil.PduFactory, a library optimized for DIS protocol standards.
A custom pduToJson method using StringBuilder is implemented for serializing PDU data into a JSON string before sending it to Kafka. This manual, direct-to-string approach avoids the reflection overhead common in generic JSON libraries (like Jackson or GSON), offering significant performance gains for the high-rate, well-defined structure of PDU data.
DIS timestamps are corrected from a signed 32-bit integer to an unsigned 32-bit representation (stored as a long) to accurately reflect absolute DIS time, ensuring data integrity for time-sensitive analysis.
Kafka as a High-Performance Buffer: Decoded PDUs are published to an Apache Kafka topic (dis-pdus) by the KafkaProducerService. Kafka serves as a distributed, resilient, and scalable buffer that decouples the ingestion stage from the processing stage. This is a critical architectural choice that allows the system to absorb unpredictable bursts of incoming PDUs, smooth out the load, and prevent data loss if downstream services are temporarily slow or unavailable.
Real-time Ingestion Metrics for Observability: The DisMetricsTracker component provides real-time insights into ingestion performance. It uses ConcurrentLinkedDeque and AtomicLong for efficient, thread-safe tracking of PDU reception rates and timestamps without introducing lock contention, which is crucial for maintaining high performance.
Efficient and Scalable Data Processing:
Concurrent Kafka Consumption for Parallel Processing: The data-processing-service is configured with a @KafkaListener that runs with a concurrency of 3 (concurrency = "3" in KafkaConsumerConfig.java). This enables parallel processing of messages from different Kafka partitions, dramatically improving throughput. As the workload grows, this concurrency level can be increased, and more instances of the service can be deployed to scale out horizontally.
Specialized PDU Parsers (Strategy Pattern): The service employs a PduParserFactory that selects a specific parser (e.g., EntityStatePduParser, FirePduParser) based on the PDU type. This implementation of the Strategy pattern is highly efficient, as it avoids complex conditional logic and allows for optimized, type-specific data extraction and transformation.
Optimized Database Persistence: Processed data is persisted to a PostgreSQL database using Spring Data JPA. While standard JPA operations are used, the database schema is designed for efficient writes. For instance, using numeric primary keys and appropriate indexing on frequently queried columns (like timestamp) ensures that write operations remain fast even as the tables grow.
Stateless Services and Horizontal Scalability (Kubernetes):
Stateless Design: All core microservices (data-ingestion-service, data-processing-service, user-service, data-acquisition-service) are designed to be stateless. They do not store any session or transaction data locally, instead relying on external systems like Kafka and PostgreSQL for state management. This is a fundamental prerequisite for effective scaling.
Horizontal Pod Autoscaler (HPA): Each service is managed by a Kubernetes Horizontal Pod Autoscaler (HPA). The HPAs are configured to monitor CPU utilization and automatically increase or decrease the number of running pods based on real-time load. This ensures that the system can dynamically adapt to changes in data volume, maintaining performance without manual intervention and optimizing resource usage.
User Authentication and Authorization:
Stateless JWT-Based Authentication: The user-service implements a stateless authentication mechanism using JSON Web Tokens (JWT). After a user successfully authenticates with their credentials, the service issues a signed JWT. This token is then sent with subsequent requests to prove identity. This approach is highly performant and scalable, as it eliminates the need for a server-side session store.
Efficient Authorization with Spring Security: The service leverages Spring Security for robust and efficient authorization. Once a user's JWT is validated, their roles and permissions are loaded into the security context. This allows for fine-grained access control to be enforced at the API endpoint level with minimal overhead.
The Kong API Gateway works in tandem with the user-service through a comprehensive Firebase JWT authentication system. Kong is configured with a custom jwt-firebase plugin that validates Firebase JWTs at the edge, automatically fetching and rotating Firebase public keys for signature verification. The gateway implements selective authentication where health endpoints remain public while data endpoints require valid Firebase tokens. Upon successful JWT validation, Kong forwards user context via headers (X-User-ID, X-User-Email, X-Consumer-ID) to downstream services, completely offloading authentication processing from backend services. This edge-level authentication, combined with rate limiting and CORS configuration, significantly enhances both performance and security by preventing unauthenticated traffic from reaching upstream services.Integration with Kong API Gateway: 

Efficient Querying and Data Retrieval:
Optimized Queries in Data Acquisition Service: The data-acquisition-service is responsible for serving data to clients. It contains optimized JPA queries and, where necessary, native SQL queries to perform efficient aggregations and time-series analysis directly in the database. This minimizes the amount of data that needs to be transferred and processed at the application layer.
Kong API Gateway for Traffic Management: Kong acts as the single entry point for all external traffic across local, staging, and production environments. It implements environment-specific configurations through Kubernetes overlays, handling sophisticated routing, rate-limiting (1000 requests/minute, 10000/hour), CORS policies, and Firebase JWT authentication. The gateway features a custom jwt-firebase plugin with automatic key rotation, comprehensive logging for debugging, and user context forwarding to backend services. Kong's declarative configuration approach ensures consistent behavior across environments while offloading authentication, authorization, and traffic management concerns from backend services. This architectural pattern allows microservices to focus exclusively on their core business logic, dramatically improving overall system security, performance, and maintainability.

Optimized Query Response Time:
The data-acquisition-service provides REST APIs for querying historical and aggregated PDU data stored in PostgreSQL.
Repository methods like findByTimestampBetween in EntityStateRepository and FireEventRepository are used for time-range queries. The efficiency of these queries is heavily dependent on appropriate database indexing on the timestamp column of the entity_state_record and fire_event_record tables. Such indexing is a standard database optimization practice and crucial for achieving acceptable query performance, especially as the dataset grows.
The /api/acquisition/metrics endpoint, handled by MetricsService.java, performs aggregations (total packets, average rate, peak load). Currently, this involves fetching lists of records and performing calculations in the application layer. For very large datasets or complex aggregations, this could be further optimized by leveraging native SQL queries or JPA Criteria API to perform aggregations directly at the database level.
The /api/acquisition/realtime endpoint makes an HTTP call via RestTemplate to an internal endpoint in data-ingestion-service (/internal/metrics/realtime) to fetch live PDU ingestion metrics. This internal HTTP call should be low-latency due to in-cluster communication.
Scalability through Kubernetes and HPA:
The entire platform is containerized and deployed on Google Kubernetes Engine (GKE), a managed Kubernetes service. This microservices architecture allows for independent scaling of each service.
Horizontal Pod Autoscalers (HPAs) are configured for data-ingestion-service, data-processing-service, data-acquisition-service and cap-user-service. These HPAs are set to scale the number of pods for each service (e.g., minReplicas: 1, maxReplicas: 2) based on CPU utilization, targeting 70 - 85% of the requested CPU, and 90% of mem. This allows the system to dynamically adjust its capacity based on processing load.

Figure 4.1.a: HPA Scaling
Resource Management: Kubernetes Deployments for each service define CPU and memory requests and limits (e.g., requests: cpu: "100m", limits: cpu: "500m"). This ensures pods are allocated necessary resources and prevents resource starvation or over-consumption, contributing to predictable performance.

Figure 4.1.a: Resource limits
Scalable Backend Infrastructure: Kafka, Zookeeper and Postgres are deployed as StatefulSets. While currently configured with single replicas for simplicity, their StatefulSet nature and Kafka's inherent distributed design allow for horizontal scaling to handle increased message throughput in a production environment. PostgreSQL can also be scaled (e.g., read replicas), though the current deployment uses a single instance.

Figure 4.1.b: Stateful sets
Query Response Time 
Database Querying: The data-acquisition-service uses Spring Data JPA repositories to query the PostgreSQL database. Performance for time-based queries relies heavily on database indexing on the timestamp column of the entity_state_record and fire_event_record tables. While not explicitly defined in the provided code, such indexing is a critical prerequisite for meeting performance goals with large datasets.
Metrics Aggregation: The /api/acquisition/metrics endpoint calculates aggregations by fetching records from the database and processing them in the application layer. For extremely large time windows, this could be optimized by pushing aggregation logic down to the database using custom native queries.

Figure 4.1.c: Aggregated metrics
Potential Performance Enhancements:
Database Optimizations: Ensure comprehensive indexing on PostgreSQL tables, especially on timestamp columns and any other frequently queried fields. Analyze query plans for critical queries to identify and resolve bottlenecks.
Batch Operations: For high-volume writes to PostgreSQL in data-processing-service, explicitly configure JDBC batching or leverage Spring Data JPA's batch capabilities to reduce database round trips.
In-Memory Caching: For frequently accessed, relatively static data or common query results in data-acquisition-service, consider implementing a caching layer (e.g., using Redis or Caffeine) to reduce database load and improve response times.
Advanced Kafka Consumer Tuning: Fine-tune Kafka consumer properties (e.g., fetch.min.bytes, fetch.max.wait.ms, max.poll.records) in data-processing-service for optimal throughput based on message size and processing characteristics.
Connection Pooling: Verify and optimize database connection pool settings for each service to ensure efficient connection management under concurrent load.
